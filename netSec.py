import seaborn as sn
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, RandomForestClassifier, GradientBoostingClassifier
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from sklearn.tree import DecisionTreeClassifier
import pandas as pd

data = pd.read_csv('data.csv')

print(data.columns)

print(data.isna().sum())

print(data.describe())

print(data.info())

import matplotlib.pyplot as plt

missing_values = data.isna().sum()
missing_values.plot(kind='bar', figsize=(10, 6))
plt.title('Missing Values in Each Column')
plt.xlabel('Columns')
plt.ylabel('Number of Missing Values')
plt.show()

data.describe().plot(kind='box', figsize=(12, 6))
plt.title('Summary Statistics')
plt.ylabel('Value')
plt.show()

data_types = data.dtypes.value_counts()
data_types.plot(kind='bar', figsize=(8, 6))
plt.title('Data Types Distribution')
plt.xlabel('Data Types')
plt.ylabel('Count')
plt.show()

data['z-scores'] = (data.asm_commands_add - data.asm_commands_add.mean()) / (data.asm_commands_add.std())

df = data[(data['z-scores'] > -3) & (data['z-scores'] < 3)]

q1 = df.asm_commands_add.quantile(0.25)
q3 = df.asm_commands_add.quantile(0.75)

iqr = q3 - q1

upper = q3 + 1.5 * iqr
lower = q1 - 1.5 * iqr

df = df[(df.asm_commands_add < upper) & (df.asm_commands_add > lower)]


q_1=df.asm_commands_add.quantile(0.25)
q_3=df.asm_commands_add.quantile(0.75)
iq_r=q_3-q_1
upper_=q_3+1.5*iq_r
lower_=q_1-1.5*iq_r
df=df[(df.asm_commands_add < upper_)&(df.asm_commands_add >lower_)]

q_11=df.asm_commands_add.quantile(0.25)
q_33=df.asm_commands_add.quantile(0.75)
i_r=q_33-q_11
upper_bound=q_33+1.5*i_r
lower_bound=q_11-1.5*i_r
df=df[(df.asm_commands_add < upper_bound)&(df.asm_commands_add >lower_bound)]

q11=df.asm_commands_add.quantile(0.25)
q33=df.asm_commands_add.quantile(0.75)
ir=q33-q11
upperbound=q33+1.5*ir
lowerbound=q11-1.5*ir
df=df[(df.asm_commands_add < upperbound)&(df.asm_commands_add >lowerbound)]

q111=df.asm_commands_add.quantile(0.25)
q333=df.asm_commands_add.quantile(0.75)
i=q333-q111
upperbounds=q333+1.5*i
lowerbounds=q111-1.5*i
df=df[(df.asm_commands_add < upperbounds)&(df.asm_commands_add >lowerbounds)]

q1111=df.asm_commands_add.quantile(0.25)
q3333=df.asm_commands_add.quantile(0.75)
ii=q3333-q1111
upperboundss=q3333+1.5*ii
lowerboundss=q1111-1.5*ii
df=df[(df.asm_commands_add < upperboundss)&(df.asm_commands_add >lowerboundss)]

q=df.asm_commands_add.quantile(0.25)
Q=df.asm_commands_add.quantile(0.75)
I=q-q
upperboun=q+1.5*I
lowerboundss=Q-1.5*I
df=df[(df.asm_commands_add < upperboundss)&(df.asm_commands_add >lowerboundss)]

print('------------------------------')
df['z-scores']=(df.asm_commands_call-df.asm_commands_call.mean())/(data.asm_commands_call.std())
df=df[(df['z-scores'] >-3)&(df['z-scores']<3)]
q1_1=df.asm_commands_call.quantile(0.25)
q3_3=df.asm_commands_call.quantile(0.75)
ii_qr=q3_3-q1_1
uppe_r=q3_3+1.5*ii_qr
lowe_r=q1_1-1.5*ii_qr
df=df[(df.asm_commands_call < uppe_r)&(df.asm_commands_add >lowe_r)]

df['z-scores']=(df.asm_commands_cld-df.asm_commands_cld.mean())/(data.asm_commands_cld.std())
df=df[(df['z-scores'] >-3)&(df['z-scores']<3)]
qi_1=df.asm_commands_cld.quantile(0.25)
qi_3=df.asm_commands_cld.quantile(0.75)
i1=qi_3-qi_1
up=qi_3+1.5*i1
lo=qi_1-1.5*i1
df=df[(df.asm_commands_cld <up)&(df.asm_commands_cld >lo)]

qii_1=df.asm_commands_cld.quantile(0.25)
qii_3=df.asm_commands_cld.quantile(0.75)
i11=qii_3-qii_1
uppi=qii_3+1.5*i11
lowe=qii_1-1.5*i11
df=df[(df.asm_commands_cld <uppi)&(df.asm_commands_cld >lowe)]

df['z-scores']=(df.asm_commands_cli-df.asm_commands_cli.mean())/(data.asm_commands_cli.std())
df=df[(df['z-scores'] >-3)&(df['z-scores']<3)]
qiq_1=df.asm_commands_cli.quantile(0.25)
qiq_3=df.asm_commands_cli.quantile(0.75)
i1q=qiq_3-qiq_1
upq=qiq_3+1.5*i1q
loq=qiq_1-1.5*i1q
df=df[(df.asm_commands_cli <upq)&(df.asm_commands_cli >loq)]

qiiq_1=df.asm_commands_cli.quantile(0.25)
qiiq_3=df.asm_commands_cli.quantile(0.75)
i11q=qiiq_3-qiiq_1
uppiq=qiiq_3+1.5*i11q
loweq=qiiq_1-1.5*i11q
df=df[(df.asm_commands_cli <uppiq)&(df.asm_commands_cli >loweq)]
print(data.shape)
print(df.shape)

for i in data.select_dtypes(include='number').columns.values:
    sn.boxenplot(data[i])
    plt.show()

for i in data.select_dtypes(include='number').columns.values:
    sn.distplot(data[i])
    plt.show()

for i in data.select_dtypes(include='number').columns.values:
        sn.ecdfplot(data[i])
        plt.show()

lab=LabelEncoder()
df['class']=lab.fit_transform(df['Class'])
x=df[['asm_commands_add','asm_commands_cld','asm_commands_cli','asm_commands_cmp','asm_commands_daa','asm_commands_dec','asm_commands_fchs','asm_commands_cdq','asm_commands_call','asm_commands_push','asm_commands_sal','line_count_asm','size_asm',
      'asm_commands_in','asm_commands_inc','asm_commands_jnb','asm_commands_jz','asm_commands_or','asm_commands_rep','asm_commands_ret','asm_commands_stc'
      ,'asm_commands_stos','asm_commands_test']]
colms=['asm_commands_add','asm_commands_cld','asm_commands_cli','asm_commands_cmp','asm_commands_daa','asm_commands_dec','asm_commands_fchs','asm_commands_cdq','asm_commands_call','asm_commands_push','asm_commands_sal','line_count_asm','size_asm',
      'asm_commands_in','asm_commands_inc','asm_commands_jnb','asm_commands_jz','asm_commands_or','asm_commands_rep','asm_commands_ret','asm_commands_stc'
      ,'asm_commands_stos','asm_commands_test']

for i in colms:
    for j in colms:
        plt.plot(df[i],marker='o',label=f'{i}',color='red')
        plt.plot(df[j],marker='x',label=f'{j}',color='blue')
        plt.title(f'{i} vs  {j}')
        plt.legend()
        plt.show()

sn.countplot(data['Class'])
plt.show()

y=df['class']
print(y.value_counts())
x_train,x_test,y_train,y_test=train_test_split(x,y)
from sklearn.linear_model import LogisticRegression
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, BaggingClassifier

lr = LogisticRegression(max_iter=200)
lr.fit(x_train, y_train)
print('Logistic Regression：', lr.score(x_test, y_test))

xgb = XGBClassifier()
xgb.fit(x_train, y_train)
print("XGBoost Classifier：", xgb.score(x_test, y_test))

lgb = LGBMClassifier()
lgb.fit(x_train, y_train)
print('LightGBM Classifier:', lgb.score(x_test, y_test))

tree = DecisionTreeClassifier(criterion='entropy', max_depth=1)
tree.fit(x_train, y_train)
print('Decision Tree Classifier:', tree.score(x_test, y_test))

rforest = RandomForestClassifier(criterion='entropy')
rforest.fit(x_train, y_train)
print('Random Forest Classifier：', rforest.score(x_test, y_test))

adb = AdaBoostClassifier()
adb.fit(x_train, y_train)
print('Ada Boost Classifier：', adb.score(x_test, y_test))

grb = GradientBoostingClassifier()
grb.fit(x_train, y_train)
print('Gradient Boosting Classifier：', grb.score(x_test, y_test))

bag = BaggingClassifier()
bag.fit(x_train, y_train)
print('Bagging Classifier:', bag.score(x_test, y_test))
print('-----------------------------------')


x=df[['asm_commands_add','asm_commands_cld','asm_commands_cli','asm_commands_cdq','asm_commands_call','asm_commands_push','asm_commands_daa','asm_commands_sal','line_count_asm','size_asm',]]
y=pd.get_dummies(df['Class'])
X=df[['asm_commands_add','asm_commands_cld','asm_commands_cli','asm_commands_cmp','asm_commands_daa','asm_commands_dec','asm_commands_fchs','asm_commands_cdq','asm_commands_call','asm_commands_push','asm_commands_sal','line_count_asm','size_asm',
      'asm_commands_in','asm_commands_inc','asm_commands_jnb','asm_commands_jz','asm_commands_or','asm_commands_rep','asm_commands_ret','asm_commands_stc'
      ,'asm_commands_stos','asm_commands_test']]
Y=pd.get_dummies(df['class'])
x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.25)
